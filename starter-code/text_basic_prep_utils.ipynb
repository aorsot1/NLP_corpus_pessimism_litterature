{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28ee1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f792f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class clean():\n",
    "    ''' A class with methods to clean text scrapped from the web.\n",
    "    '''\n",
    "    def __init__(self, text):\n",
    "        ''' Initializing the input of text\n",
    "        '''\n",
    "        self.text = text\n",
    "     \n",
    "    def removeNonAscii(self):\n",
    "        ''' Removing ASCII characters\n",
    "        '''\n",
    "        self.text = \"\".join(i for i in self.text if  ord(i)<128)\n",
    "        return self\n",
    "\n",
    "    def make_lower_case(self):\n",
    "        ''' Converting to lower case\n",
    "        '''\n",
    "        self.text = self.text.lower()\n",
    "        return self\n",
    "\n",
    "    def remove_stop_words(self):\n",
    "        ''' Removing stop words\n",
    "        '''\n",
    "        self.text = self.text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        self.text = [w for w in self.text if not w in stops]\n",
    "        self.text = \" \".join(self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_html(text):\n",
    "        ''' Removing all html tag and keep content\n",
    "        '''\n",
    "        html_pattern = re.compile('<.*?>')\n",
    "        self.text = html_pattern.sub(r'', self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_punctuation(text):\n",
    "        ''' Removing all punctuation\n",
    "        '''\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        self.text = tokenizer.tokenize(self.text)\n",
    "        self.text = \" \".join(self.text)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee349cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class prep():\n",
    "    ''' A class to prep the text data for various applications.\n",
    "    '''\n",
    "    def __init__(self, text):\n",
    "        ''' Initializing the input of text\n",
    "        '''\n",
    "        self.text = text\n",
    "    \n",
    "    def tokenize(self):\n",
    "        ''' Tokenizing the text into a bag of words\n",
    "        '''\n",
    "        return word_tokenize(self.text)\n",
    "    \n",
    "    def stemming(self):\n",
    "        ''' Getting the stem (root) of each words regadless of grammar\n",
    "        '''\n",
    "        stemmer = PorterStemmer()\n",
    "        return [stemmer.stem(word) for word in self.tokenize()]\n",
    "    \n",
    "    def lemmatizing(self):\n",
    "        ''' Getting the stem (root) of each words considering grammar\n",
    "        '''\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        return [lemmatizer.lemmatize(word) for word in self.tokenize()]\n",
    "    \n",
    "    def word_tagging(self):\n",
    "        ''' Categoring the words wether they are noun, verb, etc.\n",
    "        '''\n",
    "        return nltk.pos_tag(self.tokenize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b51ff53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class visual():\n",
    "    ''' A class to visualize text using the bag of words\n",
    "    '''\n",
    "    def __init__(self, tokens):\n",
    "        ''' Initializing the bag of words\n",
    "        '''\n",
    "        self.tokens = tokens\n",
    "        \n",
    "    def word_freq(self, reverse=True):\n",
    "        ''' Obtain the word frequency in descending order. Could get the ascending by\n",
    "        setting reverse to False\n",
    "        '''\n",
    "        freq = Counter(tokens)\n",
    "        self.sorted_freq = dict(sorted(freq.items(), key=lambda x: x[1], reverse=True))\n",
    "        return self.sorted_freq\n",
    "        \n",
    "    def freq_plot(self, top=25):\n",
    "        ''' Obtain a frequency bar chart showing the words and their equivalent count \n",
    "        within the text\n",
    "        '''\n",
    "        top_words = list(self.sorted_freq.keys())[:top]\n",
    "        top_freq = list(self.sorted_freq.values())[:top]\n",
    "        sns.barplot(y=top_words, x=top_freq)\n",
    "        plt.show()\n",
    "    \n",
    "    def word_cloud(self):\n",
    "        ''' Obtain a word cloud from the sorted frequency of the bag of words.\n",
    "        '''\n",
    "        wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, \n",
    "                          background_color='black', colormap='Set2', \n",
    "                          collocations=False, stopwords = STOPWORDS)\n",
    "        wordcloud.generate_from_frequencies(self.sorted_freq)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(wordcloud) \n",
    "        plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
