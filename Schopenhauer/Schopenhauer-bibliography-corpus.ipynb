{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "758cd899-bfd5-4be6-a65a-666bcf8f7a63",
    "_uuid": "d2302def-fe6a-4a69-9656-1cddb7559487",
    "execution": {
     "iopub.execute_input": "2021-06-07T15:31:20.177822Z",
     "iopub.status.busy": "2021-06-07T15:31:20.177446Z",
     "iopub.status.idle": "2021-06-07T15:31:20.185926Z",
     "shell.execute_reply": "2021-06-07T15:31:20.184498Z",
     "shell.execute_reply.started": "2021-06-07T15:31:20.177789Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akoua Orsot\\Anaconda3\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.4) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Akoua\n",
      "[nltk_data]     Orsot\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import urllib3.request\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Art of Literature\n",
    "lit = requests.get('https://www.gutenberg.org/cache/epub/10714/pg10714.txt')\n",
    "beg = lit.text.find('ON AUTHORSHIP.')\n",
    "end = lit.text.find('End of Project Gutenberg')\n",
    "book1 = lit.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE ART OF CONTROVERSY\n",
    "cont = requests.get('https://www.gutenberg.org/cache/epub/10731/pg10731.txt')\n",
    "beg = cont.text.find('THE ART OF CONTROVERSY.')\n",
    "end = cont.text.find('comprehensive understanding of it.')\n",
    "book2 = cont.text[beg:end]+'comprehensive understanding of it.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counsels and Maxims\n",
    "maxs = requests.get('https://www.gutenberg.org/cache/epub/10715/pg10715.txt')\n",
    "beg = maxs.text.find('INTRODUCTION.')\n",
    "end = maxs.text.find('End of Project Gutenberg')\n",
    "book3 = maxs.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Studies in Pessimism\n",
    "pess = requests.get('https://www.gutenberg.org/cache/epub/10732/pg10732.txt')\n",
    "beg = pess.text.find('ON THE SUFFERINGS OF THE WORLD.')\n",
    "end = pess.text.find('***END OF THE PROJECT GUTENBERG EBOOK')\n",
    "book4 = pess.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ON HUMAN NATURE\n",
    "human = requests.get('https://www.gutenberg.org/cache/epub/10739/pg10739.txt')\n",
    "beg = human.text.find('HUMAN NATURE.\\r\\n\\r\\n\\r\\nTruths')\n",
    "end = human.text.find('End of the Project Gutenberg EBook')\n",
    "book5 = human.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ON The Wisdom of Life\n",
    "wisdom = requests.get('https://www.gutenberg.org/cache/epub/10741/pg10741.txt')\n",
    "beg = wisdom.text.find('INTRODUCTION.')\n",
    "end = wisdom.text.find('End of the Project Gutenberg EBook')\n",
    "book6 = wisdom.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Religion, A Dialogue\n",
    "wisdom = requests.get('https://www.gutenberg.org/cache/epub/10833/pg10833.txt')\n",
    "beg = wisdom.text.find('RELIGION.\\r\\n\\r\\nA DIALOGUE.\\r\\n\\r\\n\\r\\n_Demopheles_. ')\n",
    "end = wisdom.text.find('***END OF THE PROJECT GUTENBERG EBOOK')\n",
    "book7 = wisdom.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essays (Notes to add)\n",
    "esy = requests.get('https://www.gutenberg.org/files/11945/11945-0.txt')\n",
    "beg = esy.text.find('ESSAYS OF SCHOPENHAUER.')\n",
    "end = esy.text.find('End of Project Gutenberg')\n",
    "book8 = esy.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# World as Will 1\n",
    "will1 = requests.get('https://www.gutenberg.org/files/38427/38427-0.txt')\n",
    "beg = will1.text.find('PREFACE TO THE FIRST EDITION.')\n",
    "end = will1.text.find('***END OF THE PROJECT GUTENBERG EBOOK')\n",
    "book9 = will1.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# World as Will 2\n",
    "will2 = requests.get('https://www.gutenberg.org/files/40097/40097-0.txt')\n",
    "beg = will2.text.find('APPENDIX: CRITICISM OF THE KANTIAN PHILOSOPHY.')\n",
    "end = will2.text.find('***END OF THE PROJECT GUTENBERG EBOOK')\n",
    "book10 = will2.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# World as Will 3\n",
    "will3 = requests.get('https://www.gutenberg.org/files/40868/40868-0.txt')\n",
    "beg = will3.text.find('SUPPLEMENTS TO THE SECOND BOOK.')\n",
    "end = will3.text.find('***END OF THE PROJECT GUTENBERG EBOOK')\n",
    "book11 = will3.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Basis of Morality\n",
    "mor = requests.get('https://www.gutenberg.org/files/44929/44929-0.txt')\n",
    "beg = mor.text.find('The question advanced by the Royal Society,')\n",
    "end = mor.text.find('End of Project Gutenberg')\n",
    "book12 = mor.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On the Fourfold Root\n",
    "four = requests.get('https://www.gutenberg.org/files/50966/50966-0.txt')\n",
    "beg = four.text.find('The divine Plato and the marvellous Kant')\n",
    "end = four.text.find('End of the Project Gutenberg EBook')\n",
    "book13 = four.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T15:31:25.065775Z",
     "iopub.status.busy": "2021-06-07T15:31:25.065471Z",
     "iopub.status.idle": "2021-06-07T15:31:25.083101Z",
     "shell.execute_reply": "2021-06-07T15:31:25.079082Z",
     "shell.execute_reply.started": "2021-06-07T15:31:25.065746Z"
    }
   },
   "outputs": [],
   "source": [
    "#Utitlity functions for removing ASCII characters, converting lower case, removing stop words, html and punctuation from description\n",
    "def _removeNonAscii(s):\n",
    "    return \"\".join(i for i in s if  ord(i)<128)\n",
    "\n",
    "def make_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['The Art of Literature', 'The Art of Controversy',\n",
    "          'Counsels and Maxims', 'Studies in Pessimism',\n",
    "          'On Human Nature', 'On the Wisdom of Life', \n",
    "          'Religion, A dialogue', 'Essays',\n",
    "          'The World As Will And Idea (Vol. 1 of 3)',\n",
    "          'The World As Will And Idea (Vol. 2 of 3)',\n",
    "          'The World As Will And Idea (Vol. 3 of 3)',\n",
    "          'The Basis of Morality', \n",
    "          'On the Fourfold Root of the Principle of Sufficient Reason and On the Will in Nature']\n",
    "\n",
    "publish_dates = [1890, 1831, 1851, \n",
    "                 1851, 1851, 1851, \n",
    "                 1851, 1851, 1819, \n",
    "                 1844, 1844, 1840, \n",
    "                 1813]\n",
    "\n",
    "texts = [book1,book2,book3,book4,\n",
    "         book5,book6,book7,book8,\n",
    "         book9,book10,book11,book12, \n",
    "         book13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T15:31:25.085983Z",
     "iopub.status.busy": "2021-06-07T15:31:25.085397Z",
     "iopub.status.idle": "2021-06-07T15:31:26.210438Z",
     "shell.execute_reply": "2021-06-07T15:31:26.209046Z",
     "shell.execute_reply.started": "2021-06-07T15:31:25.085926Z"
    }
   },
   "outputs": [],
   "source": [
    "books_dict = {'book_title': titles,\n",
    "              'publishing_date': publish_dates,\n",
    "              'text': texts}\n",
    "df = pd.DataFrame.from_dict(data=books_dict, orient='columns')\n",
    "df['text_clean'] = df['text'].astype(str)\n",
    "df['text_clean'] = df['text_clean'].apply(_removeNonAscii)\n",
    "df['text_clean'] = df['text_clean'].apply(func = make_lower_case)\n",
    "df['text_clean'] = df['text_clean'].apply(func = remove_stop_words)\n",
    "df['text_clean'] = df['text_clean'].apply(func=remove_punctuation)\n",
    "df['text_clean'] = df['text_clean'].apply(func=remove_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T15:32:40.823935Z",
     "iopub.status.busy": "2021-06-07T15:32:40.823459Z",
     "iopub.status.idle": "2021-06-07T15:32:41.218363Z",
     "shell.execute_reply": "2021-06-07T15:32:41.217173Z",
     "shell.execute_reply.started": "2021-06-07T15:32:40.823875Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('Schopenhauer_works_corpus.csv', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
