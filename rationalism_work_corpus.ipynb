{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "758cd899-bfd5-4be6-a65a-666bcf8f7a63",
    "_uuid": "d2302def-fe6a-4a69-9656-1cddb7559487",
    "execution": {
     "iopub.execute_input": "2021-06-07T15:31:20.177822Z",
     "iopub.status.busy": "2021-06-07T15:31:20.177446Z",
     "iopub.status.idle": "2021-06-07T15:31:20.185926Z",
     "shell.execute_reply": "2021-06-07T15:31:20.184498Z",
     "shell.execute_reply.started": "2021-06-07T15:31:20.177789Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Akoua\n",
      "[nltk_data]     Orsot\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import urllib3.request\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descartes - discourses\n",
    "dscm = requests.get('https://www.gutenberg.org/cache/epub/59/pg59.txt')\n",
    "beg = dscm.text.find('If this Discourse appear too long to be read at once')\n",
    "end = dscm.text.find('End of the Project Gutenberg EBook')\n",
    "book1 = dscm.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descartes - principles\n",
    "dspr = requests.get('https://www.gutenberg.org/cache/epub/4391/pg4391.txt')\n",
    "beg = dspr.text.find('Sir,--The version of my principles which you have been')\n",
    "end = dspr.text.find('End of Project Gutenberg')\n",
    "book2 = dspr.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spinoza - ethics\n",
    "seth = requests.get('https://www.gutenberg.org/cache/epub/3800/pg3800.txt')\n",
    "beg = seth.text.find('PART I. CONCERNING GOD.')\n",
    "end = seth.text.find('End of the Project Gutenberg EBook')\n",
    "book3 = seth.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spinoza - improve understanding\n",
    "simp = requests.get('https://www.gutenberg.org/cache/epub/1016/pg1016.txt')\n",
    "beg = simp.text.find('This notice to the reader ')\n",
    "end = simp.text.find(\"Notes by Volunteer.\")\n",
    "book4 = simp.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leibniz - theodicy\n",
    "lety = requests.get('https://www.gutenberg.org/cache/epub/17147/pg17147.txt')\n",
    "beg = lety.text.find('It has ever been seen that men in general have resorted to outward forms')\n",
    "end = lety.text.find('[443]')\n",
    "book5 = lety.text[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Discourse on the Method', 'Selections from the Principles of Philosophy', \n",
    "          'Ethics', 'On the Improvement of the Understanding', \n",
    "         'Theodicy: Essays on the Goodness of God, the Freedom of Man and the Origin of Evil']\n",
    "authors = ['René Descartes', 'René Descartes', 'Baruch Spinoza', \n",
    "           'Baruch Spinoza', 'Gottfried Wilhelm Leibniz']\n",
    "publish_dates = [1637 , 1644, 1677, 1662, 1710]\n",
    "\n",
    "texts = [book1,book2,book3,book4, book5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utitlity functions for removing ASCII characters, converting lower case, removing stop words, html and punctuation from description\n",
    "def _removeNonAscii(s):\n",
    "    return \"\".join(i for i in s if  ord(i)<128)\n",
    "\n",
    "def make_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T15:31:25.085983Z",
     "iopub.status.busy": "2021-06-07T15:31:25.085397Z",
     "iopub.status.idle": "2021-06-07T15:31:26.210438Z",
     "shell.execute_reply": "2021-06-07T15:31:26.209046Z",
     "shell.execute_reply.started": "2021-06-07T15:31:25.085926Z"
    }
   },
   "outputs": [],
   "source": [
    "books_dict = {'book_title': titles,\n",
    "              'publishing_date': publish_dates,\n",
    "              'authors': authors,\n",
    "              'text': texts}\n",
    "df = pd.DataFrame.from_dict(data=books_dict, orient='columns')\n",
    "df['text_clean'] = df['text'].astype(str)\n",
    "df['text_clean'] = df['text_clean'].apply(_removeNonAscii)\n",
    "df['text_clean'] = df['text_clean'].apply(func = make_lower_case)\n",
    "df['text_clean'] = df['text_clean'].apply(func = remove_stop_words)\n",
    "df['text_clean'] = df['text_clean'].apply(func=remove_punctuation)\n",
    "df['text_clean'] = df['text_clean'].apply(func=remove_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T15:32:40.823935Z",
     "iopub.status.busy": "2021-06-07T15:32:40.823459Z",
     "iopub.status.idle": "2021-06-07T15:32:41.218363Z",
     "shell.execute_reply": "2021-06-07T15:32:41.217173Z",
     "shell.execute_reply.started": "2021-06-07T15:32:40.823875Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('Rationalism_works_corpus.csv', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
